{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading Libs :"
      ],
      "metadata": {
        "id": "C9w_tVLoL-oF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bsyn7ytGKiCH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading :"
      ],
      "metadata": {
        "id": "HwD5VRRlMGsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "csv_path_1 = \"/content/drive/MyDrive/eng.csv\"\n",
        "csv_path_2 = \"/content/drive/MyDrive/zho.csv\"\n",
        "csv_path_3 = \"/content/drive/MyDrive/urd.csv\"\n",
        "csv_path_4 = \"/content/drive/MyDrive/arb.csv\"\n",
        "csv_path_5 = \"/content/drive/MyDrive/tur.csv\"\n",
        "df = pd.read_csv(csv_path_!)\n",
        "df[\"polarization\"] = df[\"polarization\"].astype(int)"
      ],
      "metadata": {
        "id": "w-XB2YbPKwUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = train_test_split(df, test_size=0.1, random_state=42, stratify=df['polarization'])"
      ],
      "metadata": {
        "id": "DOPhelvZK5Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model & Tokenizer Loading :"
      ],
      "metadata": {
        "id": "Z0U1OPuaMLpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME_1 = \"roberta-large\"\n",
        "MODEL_NAME_2 = \"xlm-roberta-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_1)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME_1, num_labels=2)"
      ],
      "metadata": {
        "id": "XoGsVTAxLCo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Class and Training Arguments :"
      ],
      "metadata": {
        "id": "w3cquHGpMTai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PolarDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len=256):\n",
        "        self.texts = df[\"text\"].tolist()\n",
        "        self.labels = df[\"polarization\"].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "train_dataset = PolarDataset(train_data, tokenizer)\n",
        "val_dataset = PolarDataset(val_data, tokenizer)"
      ],
      "metadata": {
        "id": "4Se4o_uILFqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = df[\"polarization\"].value_counts().sort_index().tolist()\n",
        "class_weights = torch.tensor(\n",
        "    [sum(class_counts)/c for c in class_counts]\n",
        ").float().to(\"cuda\")\n",
        "\n",
        "print(\"Class Weights:\", class_weights)\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "eS0vivi2OGAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    preds = p.predictions.argmax(-1)\n",
        "    labels = p.label_ids\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"precision\": precision_score(labels, preds),\n",
        "        \"recall\": recall_score(labels, preds),\n",
        "        \"f1\": f1_score(labels, preds)\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./model\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=6,\n",
        "    gradient_accumulation_steps=4,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    report_to=[],\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_f1\",\n",
        "    greater_is_better=True,\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "-7jUr6m9OSgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training :"
      ],
      "metadata": {
        "id": "1wXksCeVMamL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "QxD1pePwSouT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results & Saving Model :"
      ],
      "metadata": {
        "id": "UXTVM_RgMf4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()\n",
        "print(\"Validation Results:\", results)\n",
        "\n",
        "trainer.save_model(\"./model\")\n",
        "tokenizer.save_pretrained(\"./model\")"
      ],
      "metadata": {
        "id": "hARggRGfVbUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving Model to Drive :"
      ],
      "metadata": {
        "id": "iFASKm2VMrFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"/content/drive/MyDrive/model/\"\n",
        "\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "PhOHaGMcbwNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual Testing :"
      ],
      "metadata": {
        "id": "0I_wLmCHMy-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/model/\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_1)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "jFdCnyYuiZZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_manual(text):\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        pred = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    label = \"Polarized\" if pred == 1 else \"Not Polarized\"\n",
        "    return pred, label\n"
      ],
      "metadata": {
        "id": "u_aFilGLidda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"trump is coruppt!!!\"\n",
        "pred, label = test_manual(text)\n",
        "\n",
        "print(\"Prediction:\", pred)\n",
        "print(\"Meaning:\", label)"
      ],
      "metadata": {
        "id": "9IaMFYI6ifb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing Metrics"
      ],
      "metadata": {
        "id": "AdfWce2sW7Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, dataset):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    labels = []\n",
        "    probs = []\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=16)\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            outputs = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
        "            pred = torch.argmax(outputs.logits, dim=1)\n",
        "            prob = torch.softmax(outputs.logits, dim=1)[:,1]\n",
        "            preds.extend(pred.tolist())\n",
        "            labels.extend(batch[\"labels\"].tolist())\n",
        "            probs.extend(prob.tolist())\n",
        "    return labels, preds, probs\n",
        "\n",
        "y_true, y_pred, y_probs = get_predictions(model, val_dataset)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.2f}\")\n",
        "plt.plot([0,1],[0,1],'--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_true, y_probs)\n",
        "pr_auc = auc(recall, precision)\n",
        "plt.plot(recall, precision, label=f\"PR AUC = {pr_auc:.2f}\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "log_history = trainer.state.log_history\n",
        "train_losses = [entry[\"loss\"] for entry in log_history if \"loss\" in entry]\n",
        "val_losses = [entry[\"eval_loss\"] for entry in log_history if \"eval_loss\" in entry]\n",
        "steps = [entry[\"step\"] for entry in log_history if \"loss\" in entry]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(steps, train_losses, label=\"Training Loss\")\n",
        "plt.plot(steps[:len(val_losses)], val_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "val_acc = [entry[\"eval_accuracy\"] for entry in log_history if \"eval_accuracy\" in entry]\n",
        "val_f1 = [entry[\"eval_f1\"] for entry in log_history if \"eval_f1\" in entry]\n",
        "val_prec = [entry[\"eval_precision\"] for entry in log_history if \"eval_precision\" in entry]\n",
        "val_rec = [entry[\"eval_recall\"] for entry in log_history if \"eval_recall\" in entry]\n",
        "epochs = list(range(1, len(val_acc)+1))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(epochs, val_acc, label=\"Accuracy\")\n",
        "plt.plot(epochs, val_f1, label=\"F1 Score\")\n",
        "plt.plot(epochs, val_prec, label=\"Precision\")\n",
        "plt.plot(epochs, val_rec, label=\"Recall\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.title(\"Validation Metrics Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "metrics_dict = {\n",
        "    \"confusion_matrix\": cm.tolist(),\n",
        "    \"roc_curve\": {\"fpr\": fpr.tolist(), \"tpr\": tpr.tolist(), \"auc\": roc_auc},\n",
        "    \"precision_recall_curve\": {\"precision\": precision.tolist(), \"recall\": recall.tolist(), \"pr_auc\": pr_auc},\n",
        "    \"train_validation_loss\": {\"steps\": steps, \"train_loss\": train_losses, \"val_loss\": val_losses},\n",
        "    \"validation_metrics_over_epochs\": {\"epochs\": epochs, \"accuracy\": val_acc, \"f1\": val_f1, \"precision\": val_prec, \"recall\": val_rec}\n",
        "}\n",
        "\n",
        "with open(\"/content/drive/MyDrive/model_metrics.json\", \"w\") as f:\n",
        "    json.dump(metrics_dict, f, indent=4)"
      ],
      "metadata": {
        "id": "0rIAoKhnX9ih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}